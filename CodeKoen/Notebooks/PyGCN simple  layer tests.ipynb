{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# IMPORT 2D NUMPY ARRAY (THAT IS AN ADJACENCY MATRIX)\n",
    "# adj = ..\n",
    "\n",
    "adj = adj + sp.eye(adj.shape[0])  # add self links for normalization purposes and convert to sparse array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "normadj = normalize(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "adj = sparse_mx_to_torch_sparse_tensor(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import features\n",
    "# features = ..\n",
    "# determine gcn dim1, dim2\n",
    "# dim1 = ..\n",
    "# dim2 = ..\n",
    "\n",
    "gc1 = GraphConvolution(dim1, dim2)\n",
    "gc1(features, adj)  # Compute one GCN round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dimension 0\n",
      "tensor([[0, 3],\n",
      "        [6, 9]])\n",
      "a dimension 1\n",
      "tensor([[ 1,  4],\n",
      "        [ 7, 10]])\n",
      "a dimension 2\n",
      "tensor([[ 2,  5],\n",
      "        [ 8, 11]])\n",
      "\n",
      "\n",
      "x dimension 0\n",
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "x dimension 1\n",
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "x dimension 2\n",
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "\n",
      "\n",
      "w1 dimension 0\n",
      "tensor([[  0,   3,   6,   9,  12,  15,  18,  21,  24,  27],\n",
      "        [ 30,  33,  36,  39,  42,  45,  48,  51,  54,  57],\n",
      "        [ 60,  63,  66,  69,  72,  75,  78,  81,  84,  87],\n",
      "        [ 90,  93,  96,  99, 102, 105, 108, 111, 114, 117]])\n",
      "w1 dimension 1\n",
      "tensor([[  1,   4,   7,  10,  13,  16,  19,  22,  25,  28],\n",
      "        [ 31,  34,  37,  40,  43,  46,  49,  52,  55,  58],\n",
      "        [ 61,  64,  67,  70,  73,  76,  79,  82,  85,  88],\n",
      "        [ 91,  94,  97, 100, 103, 106, 109, 112, 115, 118]])\n",
      "w1 dimension 2\n",
      "tensor([[  2,   5,   8,  11,  14,  17,  20,  23,  26,  29],\n",
      "        [ 32,  35,  38,  41,  44,  47,  50,  53,  56,  59],\n",
      "        [ 62,  65,  68,  71,  74,  77,  80,  83,  86,  89],\n",
      "        [ 92,  95,  98, 101, 104, 107, 110, 113, 116, 119]])\n",
      "\n",
      "\n",
      "b1 dimension 0\n",
      "tensor([[ 0,  3,  6,  9, 12, 15, 18, 21, 24, 27]])\n",
      "b1 dimension 1\n",
      "tensor([[ 1,  4,  7, 10, 13, 16, 19, 22, 25, 28]])\n",
      "b1 dimension 2\n",
      "tensor([[ 2,  5,  8, 11, 14, 17, 20, 23, 26, 29]])\n",
      "\n",
      "\n",
      "adj_x dimension 0\n",
      "tensor([[12, 15, 18, 21],\n",
      "        [36, 51, 66, 81]])\n",
      "adj_x dimension 1\n",
      "tensor([[16, 21, 26, 31],\n",
      "        [40, 57, 74, 91]])\n",
      "adj_x dimension 2\n",
      "tensor([[ 20,  27,  34,  41],\n",
      "        [ 44,  63,  82, 101]])\n",
      "\n",
      "\n",
      "out_1 dimension 0\n",
      "tensor([[ 3420,  3618,  3816,  4014,  4212,  4410,  4608,  4806,  5004,  5202],\n",
      "        [12780, 13482, 14184, 14886, 15588, 16290, 16992, 17694, 18396, 19098]])\n",
      "out_1 dimension 1\n",
      "tensor([[ 5074,  5356,  5638,  5920,  6202,  6484,  6766,  7048,  7330,  7612],\n",
      "        [14602, 15388, 16174, 16960, 17746, 18532, 19318, 20104, 20890, 21676]])\n",
      "out_1 dimension 2\n",
      "tensor([[ 6784,  7150,  7516,  7882,  8248,  8614,  8980,  9346,  9712, 10078],\n",
      "        [16480, 17350, 18220, 19090, 19960, 20830, 21700, 22570, 23440, 24310]])\n",
      "\n",
      "\n",
      "out_bias_1 dimension 0\n",
      "tensor([[ 3420,  3621,  3822,  4023,  4224,  4425,  4626,  4827,  5028,  5229],\n",
      "        [12780, 13485, 14190, 14895, 15600, 16305, 17010, 17715, 18420, 19125]])\n",
      "out_bias_1 dimension 1\n",
      "tensor([[ 5075,  5360,  5645,  5930,  6215,  6500,  6785,  7070,  7355,  7640],\n",
      "        [14603, 15392, 16181, 16970, 17759, 18548, 19337, 20126, 20915, 21704]])\n",
      "out_bias_1 dimension 2\n",
      "tensor([[ 6786,  7155,  7524,  7893,  8262,  8631,  9000,  9369,  9738, 10107],\n",
      "        [16482, 17355, 18228, 19101, 19974, 20847, 21720, 22593, 23466, 24339]])\n",
      "\n",
      "\n",
      "activation dimension 0\n",
      "tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0, 19125]])\n",
      "activation dimension 1\n",
      "tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0, 21704]])\n",
      "activation dimension 2\n",
      "tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0, 23466, 24339]])\n",
      "\n",
      "\n",
      "tensor([[    0,     0,     0],\n",
      "        [    0,     0,     0],\n",
      "        [    0,     0,     0],\n",
      "        [    0,     0,     0],\n",
      "        [    0,     0,     0],\n",
      "        [    0,     0,     0],\n",
      "        [    0,     0,     0],\n",
      "        [    0,     0,     0],\n",
      "        [ 5028,  7355,  9738],\n",
      "        [ 5229,  7640, 10107]])\n",
      "tensor([[[  0,   1,   2],\n",
      "         [  3,   4,   5],\n",
      "         [  6,   7,   8],\n",
      "         [  9,  10,  11],\n",
      "         [ 12,  13,  14],\n",
      "         [ 15,  16,  17],\n",
      "         [ 18,  19,  20],\n",
      "         [ 21,  22,  23],\n",
      "         [ 24,  25,  26],\n",
      "         [ 27,  28,  29]],\n",
      "\n",
      "        [[ 30,  31,  32],\n",
      "         [ 33,  34,  35],\n",
      "         [ 36,  37,  38],\n",
      "         [ 39,  40,  41],\n",
      "         [ 42,  43,  44],\n",
      "         [ 45,  46,  47],\n",
      "         [ 48,  49,  50],\n",
      "         [ 51,  52,  53],\n",
      "         [ 54,  55,  56],\n",
      "         [ 57,  58,  59]],\n",
      "\n",
      "        [[ 60,  61,  62],\n",
      "         [ 63,  64,  65],\n",
      "         [ 66,  67,  68],\n",
      "         [ 69,  70,  71],\n",
      "         [ 72,  73,  74],\n",
      "         [ 75,  76,  77],\n",
      "         [ 78,  79,  80],\n",
      "         [ 81,  82,  83],\n",
      "         [ 84,  85,  86],\n",
      "         [ 87,  88,  89]],\n",
      "\n",
      "        [[ 90,  91,  92],\n",
      "         [ 93,  94,  95],\n",
      "         [ 96,  97,  98],\n",
      "         [ 99, 100, 101],\n",
      "         [102, 103, 104],\n",
      "         [105, 106, 107],\n",
      "         [108, 109, 110],\n",
      "         [111, 112, 113],\n",
      "         [114, 115, 116],\n",
      "         [117, 118, 119]]])\n",
      "adj_x shape torch.Size([2, 4, 3])\n",
      "out_1 shape torch.Size([2, 10, 3])\n"
     ]
    }
   ],
   "source": [
    "# EXPERIMENT WITH MULTIDIMENSIONAL ADJACENCY MATRIX WHERE DIMENSIONS ARE KEPT (USING EINSUM)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "n = 2 # nodes\n",
    "c = 4 # channels/features per node\n",
    "d = 3 # dimensions of the graph\n",
    "f1 = 10 # filter per dimension layer 1\n",
    "f2 = 5 # filter per dimension layer 2\n",
    "\n",
    "a = torch.arange(n*n*d).reshape(n, n, d)\n",
    "x = torch.arange(n*c).reshape(n, c, 1).repeat(1, 1, d)\n",
    "w1 = torch.arange(c*f1*d).reshape(c, f1, d)\n",
    "b1 = torch.arange(f1*d).reshape(1, f1, d)\n",
    "adj_x  = torch.einsum('ijd,jkd->ikd', a, x)\n",
    "out_1 = torch.einsum('ijd,jfd->ifd', adj_x, w1)\n",
    "out_bias_1 = out_1+b1\n",
    "activation = F.relu(out_bias_1)\n",
    "\n",
    "def print_m_per_d(name, m):\n",
    "    for i in range(m.shape[2]):\n",
    "        print(name, \"dimension\",i)\n",
    "        print(m[:,:,i])\n",
    "    print(\"\\n\")\n",
    "\n",
    "print_m_per_d(\"a\", a)\n",
    "print_m_per_d(\"x\", x)\n",
    "print_m_per_d(\"w1\", w1)\n",
    "print_m_per_d(\"b1\", b1)\n",
    "print_m_per_d(\"adj_x\", adj_x)\n",
    "print_m_per_d(\"out_1\", out_1)\n",
    "print_m_per_d(\"out_bias_1\", out_bias_1)\n",
    "print_m_per_d(\"activation\", activation)\n",
    "print(F.relu(out_bias_1[0,:,:]))\n",
    "print(w1)\n",
    "\n",
    "print(\"adj_x shape\", adj_x.shape)\n",
    "print(\"out_1 shape\", out_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next: Implement einsum transforms in codebase pygcn (from kipf)\n",
    "# Run network with input data Kristian"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
