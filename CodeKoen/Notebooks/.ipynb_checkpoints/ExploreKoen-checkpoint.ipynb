{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cameo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cobra\n",
    "import json\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cameo.load_model(\"iJO1366\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1805\n",
      "2583\n",
      "1367\n"
     ]
    }
   ],
   "source": [
    "metabolite_list = [m.id for m in model.metabolites]\n",
    "n_mets = len(model.metabolites)\n",
    "reaction_list = [r.id for r in model.reactions]\n",
    "n_reacs = len(model.reactions)\n",
    "genes_list = [r.id for r in model.genes]\n",
    "n_genes = len(model.genes)\n",
    "print(n_mets)\n",
    "print(n_reacs)\n",
    "print(n_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabolites_indices = {met: i for i, met in enumerate(metabolite_list)}\n",
    "reaction_indices = {reac: n_mets + i for i, reac in enumerate(reaction_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = cobra.util.array.create_stoichiometric_matrix(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.genes.b1377\n",
    "#model.reactions.ASO3tex\n",
    "#model.genes.b1377.knock_out\n",
    "#ax = sns.heatmap(s[:50,:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_to_adj(s):\n",
    "    num_metabolites = s.shape[0]\n",
    "    num_reactions = s.shape[1]\n",
    "    adj = np.eye(num_metabolites+num_reactions)\n",
    "    for m in range(num_metabolites):\n",
    "        reactions = np.where(s[m,:] !=0)[0]\n",
    "        for r in reactions:\n",
    "            r_ix = num_metabolites + r\n",
    "            adj[m,r_ix] = s[m,r]\n",
    "            adj[r_ix,m] = s[m,r]\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = s_to_adj(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_metabolite = np.concatenate((np.ones(n_mets), np.zeros(n_reacs)))\n",
    "features = pd.DataFrame(is_metabolite,index=[metabolite_list+reaction_list],columns=['metabolite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"xylu__L\" in metabolite_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.genes.aas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = np.zeros(shape=(4388, 4388, 3))\n",
    "#adj = np.zeros(shape=(3, 4388, 4388))\n",
    "X = np.zeros(shape=(4388, 5, 1064))\n",
    "X1 = X[:,:,0]\n",
    "\n",
    "W1 = np.zeros(shape=(5, 8))\n",
    "W2 = np.zeros(shape=(8, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = np.dot(X1,W1)\n",
    "print(S1.shape)\n",
    "L1 = np.dot(adj,S1)\n",
    "print(L1.shape)\n",
    "\n",
    "S2 = np.dot(L1,W2)\n",
    "print(S2.shape)\n",
    "L2 = np.dot(adj,S2)\n",
    "print(L2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_X = np.dot(adj, X1, axes=[1, 1]).transpose(2, 1, 0, 3)\n",
    "Z = np.dot(A_X, W1, axes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "n = 3 # nodes\n",
    "c = 4 # channels/features per node\n",
    "d = 2 # dimensions of the graph\n",
    "f1 = 2 # filter per dimension layer 1\n",
    "f2 = 5 # filter per dimension layer 2\n",
    "\n",
    "a = torch.arange(d*n*n).reshape(d, n, n)\n",
    "x = torch.arange(n*c).reshape(1, n, c)\n",
    "w1 = torch.arange(d*c*f1).reshape(d, c, f1)\n",
    "adj_x  = torch.einsum('dij,rjk->dik', a, x)  # r weglaten als niet gereshaped met dimension\n",
    "out_1 = torch.einsum('dij,djf->dif', adj_x, w1)\n",
    "\n",
    "print(\"a\\n\", a)\n",
    "print(\"\\nx\\n\", x)\n",
    "print(\"\\nadj_x\\n\", adj_x)\n",
    "print(\"\\nw1\\n\", w1)\n",
    "print(\"\\nout_1\\n\", out_1)\n",
    "print(\"\\nadj_x shape\", adj_x.shape)\n",
    "print(\"\\nout_1 shape\", out_1.shape)\n",
    "\n",
    "#Manual calculation adj_x\n",
    "#r = torch.arange(d*n*c).reshape(d, n, c)\n",
    "#r[0,:,:] = torch.mm(a[0,:,:],x)\n",
    "#r[1,:,:] = torch.mm(a[1,:,:],x)\n",
    "#print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = torch.arange(d*f1*f2).reshape(d, f1, f2)\n",
    "\n",
    "adj_x  = torch.einsum('dij,djk->dik', a, out_1)\n",
    "out_2 = torch.einsum('dij,djf->dif', adj_x, w2)\n",
    "\n",
    "print(\"\\nadj_x\\n\", adj_x)\n",
    "print(\"\\nw2\\n\", w2)\n",
    "print(\"\\nout_2\\n\", out_2)\n",
    "print(\"\\nadj_x shape\", adj_x.shape)\n",
    "print(\"\\nout_2 shape\", out_2.shape)\n",
    "\n",
    "#Manual calculation adj_x\n",
    "#r = torch.arange(d*n*f1).reshape(d, n, f1)\n",
    "#r[0,:,:] = torch.mm(a[0,:,:],output[0,:,:])\n",
    "#r[1,:,:] = torch.mm(a[1,:,:],output[1,:,:])\n",
    "#print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dimension 0\n",
      "tensor([[0, 3],\n",
      "        [6, 9]])\n",
      "a dimension 1\n",
      "tensor([[ 1,  4],\n",
      "        [ 7, 10]])\n",
      "a dimension 2\n",
      "tensor([[ 2,  5],\n",
      "        [ 8, 11]])\n",
      "\n",
      "\n",
      "x dimension 0\n",
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "x dimension 1\n",
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "x dimension 2\n",
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "\n",
      "\n",
      "w1 dimension 0\n",
      "tensor([[  0,   3,   6,   9,  12,  15,  18,  21,  24,  27],\n",
      "        [ 30,  33,  36,  39,  42,  45,  48,  51,  54,  57],\n",
      "        [ 60,  63,  66,  69,  72,  75,  78,  81,  84,  87],\n",
      "        [ 90,  93,  96,  99, 102, 105, 108, 111, 114, 117]])\n",
      "w1 dimension 1\n",
      "tensor([[  1,   4,   7,  10,  13,  16,  19,  22,  25,  28],\n",
      "        [ 31,  34,  37,  40,  43,  46,  49,  52,  55,  58],\n",
      "        [ 61,  64,  67,  70,  73,  76,  79,  82,  85,  88],\n",
      "        [ 91,  94,  97, 100, 103, 106, 109, 112, 115, 118]])\n",
      "w1 dimension 2\n",
      "tensor([[  2,   5,   8,  11,  14,  17,  20,  23,  26,  29],\n",
      "        [ 32,  35,  38,  41,  44,  47,  50,  53,  56,  59],\n",
      "        [ 62,  65,  68,  71,  74,  77,  80,  83,  86,  89],\n",
      "        [ 92,  95,  98, 101, 104, 107, 110, 113, 116, 119]])\n",
      "\n",
      "\n",
      "b1 dimension 0\n",
      "tensor([[ 0,  3,  6,  9, 12, 15, 18, 21, 24, 27]])\n",
      "b1 dimension 1\n",
      "tensor([[ 1,  4,  7, 10, 13, 16, 19, 22, 25, 28]])\n",
      "b1 dimension 2\n",
      "tensor([[ 2,  5,  8, 11, 14, 17, 20, 23, 26, 29]])\n",
      "\n",
      "\n",
      "adj_x dimension 0\n",
      "tensor([[12, 15, 18, 21],\n",
      "        [36, 51, 66, 81]])\n",
      "adj_x dimension 1\n",
      "tensor([[16, 21, 26, 31],\n",
      "        [40, 57, 74, 91]])\n",
      "adj_x dimension 2\n",
      "tensor([[ 20,  27,  34,  41],\n",
      "        [ 44,  63,  82, 101]])\n",
      "\n",
      "\n",
      "out_1 dimension 0\n",
      "tensor([[ 3420,  3618,  3816,  4014,  4212,  4410,  4608,  4806,  5004,  5202],\n",
      "        [12780, 13482, 14184, 14886, 15588, 16290, 16992, 17694, 18396, 19098]])\n",
      "out_1 dimension 1\n",
      "tensor([[ 5074,  5356,  5638,  5920,  6202,  6484,  6766,  7048,  7330,  7612],\n",
      "        [14602, 15388, 16174, 16960, 17746, 18532, 19318, 20104, 20890, 21676]])\n",
      "out_1 dimension 2\n",
      "tensor([[ 6784,  7150,  7516,  7882,  8248,  8614,  8980,  9346,  9712, 10078],\n",
      "        [16480, 17350, 18220, 19090, 19960, 20830, 21700, 22570, 23440, 24310]])\n",
      "\n",
      "\n",
      "out_bias_1 dimension 0\n",
      "tensor([[ 3420,  3621,  3822,  4023,  4224,  4425,  4626,  4827,  5028,  5229],\n",
      "        [12780, 13485, 14190, 14895, 15600, 16305, 17010, 17715, 18420, 19125]])\n",
      "out_bias_1 dimension 1\n",
      "tensor([[ 5075,  5360,  5645,  5930,  6215,  6500,  6785,  7070,  7355,  7640],\n",
      "        [14603, 15392, 16181, 16970, 17759, 18548, 19337, 20126, 20915, 21704]])\n",
      "out_bias_1 dimension 2\n",
      "tensor([[ 6786,  7155,  7524,  7893,  8262,  8631,  9000,  9369,  9738, 10107],\n",
      "        [16482, 17355, 18228, 19101, 19974, 20847, 21720, 22593, 23466, 24339]])\n",
      "\n",
      "\n",
      "activation dimension 0\n",
      "tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0, 19125]])\n",
      "activation dimension 1\n",
      "tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0, 21704]])\n",
      "activation dimension 2\n",
      "tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0, 23466, 24339]])\n",
      "\n",
      "\n",
      "tensor([[    0,     0,     0],\n",
      "        [    0,     0,     0],\n",
      "        [    0,     0,     0],\n",
      "        [    0,     0,     0],\n",
      "        [    0,     0,     0],\n",
      "        [    0,     0,     0],\n",
      "        [    0,     0,     0],\n",
      "        [    0,     0,     0],\n",
      "        [ 5028,  7355,  9738],\n",
      "        [ 5229,  7640, 10107]])\n",
      "tensor([[[  0,   1,   2],\n",
      "         [  3,   4,   5],\n",
      "         [  6,   7,   8],\n",
      "         [  9,  10,  11],\n",
      "         [ 12,  13,  14],\n",
      "         [ 15,  16,  17],\n",
      "         [ 18,  19,  20],\n",
      "         [ 21,  22,  23],\n",
      "         [ 24,  25,  26],\n",
      "         [ 27,  28,  29]],\n",
      "\n",
      "        [[ 30,  31,  32],\n",
      "         [ 33,  34,  35],\n",
      "         [ 36,  37,  38],\n",
      "         [ 39,  40,  41],\n",
      "         [ 42,  43,  44],\n",
      "         [ 45,  46,  47],\n",
      "         [ 48,  49,  50],\n",
      "         [ 51,  52,  53],\n",
      "         [ 54,  55,  56],\n",
      "         [ 57,  58,  59]],\n",
      "\n",
      "        [[ 60,  61,  62],\n",
      "         [ 63,  64,  65],\n",
      "         [ 66,  67,  68],\n",
      "         [ 69,  70,  71],\n",
      "         [ 72,  73,  74],\n",
      "         [ 75,  76,  77],\n",
      "         [ 78,  79,  80],\n",
      "         [ 81,  82,  83],\n",
      "         [ 84,  85,  86],\n",
      "         [ 87,  88,  89]],\n",
      "\n",
      "        [[ 90,  91,  92],\n",
      "         [ 93,  94,  95],\n",
      "         [ 96,  97,  98],\n",
      "         [ 99, 100, 101],\n",
      "         [102, 103, 104],\n",
      "         [105, 106, 107],\n",
      "         [108, 109, 110],\n",
      "         [111, 112, 113],\n",
      "         [114, 115, 116],\n",
      "         [117, 118, 119]]])\n",
      "adj_x shape torch.Size([2, 4, 3])\n",
      "out_1 shape torch.Size([2, 10, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "n = 2 # nodes\n",
    "c = 4 # channels/features per node\n",
    "d = 3 # dimensions of the graph\n",
    "f1 = 10 # filter per dimension layer 1\n",
    "f2 = 5 # filter per dimension layer 2\n",
    "\n",
    "a = torch.arange(n*n*d).reshape(n, n, d)\n",
    "x = torch.arange(n*c).reshape(n, c, 1).repeat(1, 1, d)\n",
    "w1 = torch.arange(c*f1*d).reshape(c, f1, d)\n",
    "b1 = torch.arange(f1*d).reshape(1, f1, d)\n",
    "adj_x  = torch.einsum('ijd,jkd->ikd', a, x)\n",
    "out_1 = torch.einsum('ijd,jfd->ifd', adj_x, w1)\n",
    "out_bias_1 = out_1+b1\n",
    "activation = F.relu(out_bias_1)\n",
    "\n",
    "def print_m_per_d(name, m):\n",
    "    for i in range(m.shape[2]):\n",
    "        print(name, \"dimension\",i)\n",
    "        print(m[:,:,i])\n",
    "    print(\"\\n\")\n",
    "\n",
    "print_m_per_d(\"a\", a)\n",
    "print_m_per_d(\"x\", x)\n",
    "print_m_per_d(\"w1\", w1)\n",
    "print_m_per_d(\"b1\", b1)\n",
    "print_m_per_d(\"adj_x\", adj_x)\n",
    "print_m_per_d(\"out_1\", out_1)\n",
    "print_m_per_d(\"out_bias_1\", out_bias_1)\n",
    "print_m_per_d(\"activation\", activation)\n",
    "print(F.relu(out_bias_1[0,:,:]))\n",
    "print(w1)\n",
    "\n",
    "print(\"adj_x shape\", adj_x.shape)\n",
    "print(\"out_1 shape\", out_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
